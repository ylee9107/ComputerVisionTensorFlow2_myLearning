{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Complex and Scrace Datasets [Notebook 2]\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When it comes to deep learning applications and its development, it is certain that Data is the most essential component of the process. By and of itself, the training data should flow into the networks unobstructed. It should contain meaningful and impactful information for the network/model. Prior to entering the network, the dataset should be prepared by various transformations and such. \n",
    "\n",
    "Today, datasets can be obtained from several complex structures or that are stored on heterogenous devices, this inherently also increases the complexity in its handling as well. While this assumes that the data is readily avaible, on the other hand, there cases where the relevant training data (images or annotations) can be unavailable or scarce. \n",
    "\n",
    "This project will venture into dealing with these kinds of cases where it also explores the framework that is available with TensorFlow to set up optimised data pipelines (tf.data API).\n",
    "\n",
    "\n",
    "## Breakdown of this Project:\n",
    "- Building efficient input pipelines with \"tf.data\" for extracting and processing data samples of all kinds. (Notebook 1 & 2)\n",
    "- Augment and render images to help compensate for scarcity of training data. (Notebook 3 & 4)\n",
    "- Different types of Doamin Adaptation methods and how it helps to train more robust models. (Notebook 5 & 6)\n",
    "- Create or generate novel images with generative models such as Variational AutoEncoders (VAEs) and Generative Adversarial Networks (GANs). (Notebook 7 & 8)\n",
    "\n",
    "## Requirements:\n",
    "1. Vispy\n",
    "2. Tensorflow 2.++\n",
    "3. Numpy\n",
    "4. OS\n",
    "\n",
    "## Dataset:\n",
    "\n",
    "The dataset can be obtain from the link: http://www.laurencemoroney.com/rock-paper-scissors-dataset/ or from https://www.tensorflow.org/datasets/catalog/rock_paper_scissors\n",
    "\n",
    "Rock Paper Scissors is a dataset containing 2,892 images of different types of hands in Rock/Paper/Scissors poses that were 3D-rendered. Each of these images are 300Ã—300 pixels in 24-bit colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Run on GPU:\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\" \n",
    "\n",
    "# Set the random set seed number: for reproducibility.\n",
    "Seed_nb = 42\n",
    "\n",
    "# Set to run or not run the code block: for code examples only. (0 = run code, and 1 = dont run code)\n",
    "dont_run = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Generating and Parsing TFRecords:\n",
    "\n",
    "As part of building an efficient input pipelines from the previous notebook. This notebook (2) will venture into __TFRecords__ where it is a format to persist datasets with TensorFlow. \n",
    "\n",
    "## 1.1 - Reminder of the ETL process:\n",
    "\n",
    "##### The following diagram below demonstrates the overall ETL process for computer vision tasks:\n",
    "\n",
    "<img src=\"Description Images/ETL_ComputerVision.png\" width=\"750\">\n",
    "\n",
    "Image Ref -> self-made.\n",
    "\n",
    "## 1.2 - About TFRecords: Transform by Parsing TFRecord Files\n",
    "\n",
    "Recalling back from the previous notebook: A more efficient way of inputting the data into the pipeline would be using the \"TFRecord\" file format, where it will store large number of images together into a binary file and make them directly accessible for read-from-disk operations. This is because the process of iterating through the image files, by the methods mentioned in the above section, are inefficient. \n",
    "\n",
    "In more detail, TFRecord files are binary files where it will aggregate the data samples such as labels, images, and metadata. It can be serialised with a \"tf.train.Example\" instance, where it is a dictionaries that names each of the data elements (features). For example:\n",
    "- {'img'; image1, 'label': label_1, ...}\n",
    "\n",
    "Each of these element or feature that a sample contains would be an instance of \"tf.train.Feature\" or of its subclasses. These types of objects will be stored as lists of bytes, floats or integers.\n",
    "To utilise TFRecord files as part of the input pipelines, the record/data can be passed with:\n",
    "- tf.data.TFRecordDataset(filename)\n",
    "\n",
    "More examples can be found in the lin: https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Writing TFRecords:\n",
    "\n",
    "From the above section, it was mentioned that TFRecords files can be stored as one binary archive with the complete dataset for training, where in doing so, it can be efficiently be reused and iterated over. The following will demonstrate the use of \"tf.data\" and \"tf.train\" APIs to process a chosen dataset into a TFRecord file.\n",
    "\n",
    "## 2.1 - Preparing the Dataset:\n",
    "\n",
    "Here, the chosen dataset will be the __Rock-Paper-Scissors__ dataset from \"tensorflow-datasets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library:\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='rock_paper_scissors',\n",
      "    version=3.0.0,\n",
      "    description='Images of hands playing rock, paper, scissor game.',\n",
      "    homepage='http://laurencemoroney.com/rock-paper-scissors-dataset',\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "    }),\n",
      "    total_num_examples=2892,\n",
      "    splits={\n",
      "        'test': 372,\n",
      "        'train': 2520,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@ONLINE {rps,\n",
      "    author = \"Laurence Moroney\",\n",
      "    title = \"Rock, Paper, Scissors Dataset\",\n",
      "    month = \"feb\",\n",
      "    year = \"2019\",\n",
      "    url = \"http://laurencemoroney.com/rock-paper-scissors-dataset\"\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load in the Dataset:\n",
    "hands_builder = tfds.builder(name=\"rock_paper_scissors\")\n",
    "hands_builder.download_and_prepare()\n",
    "\n",
    "# After the download, print out some information on the dataset:\n",
    "print(hands_builder.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"Description Images/.png\" width=\"750\">\n",
    "\n",
    "Image Ref -> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
