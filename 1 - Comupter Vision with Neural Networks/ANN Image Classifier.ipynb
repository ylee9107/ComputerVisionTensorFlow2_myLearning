{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural Network\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "This project will cover what neural networks are and its implementation in Python for the tass of basic recognition. This project will also explore the domain of computer vision and how it is an automation of extracting information from digital images. There are a lot of applications for computer vision such as control systems to be used in industry, facial filters in mobile apps, or security surveillance systems.\n",
    "\n",
    "Computer vision can also be broken down into the following:\n",
    "- Content recognition (Object Identification, Object detection and localisation, Object and instance segmentation or Pose estimation).\n",
    "- Video analysis (Instance Tracking, Action recognition, Motion estimation).\n",
    "- Content-Aware image edition.\n",
    "- Scene Reconstruction.\n",
    "\n",
    "## Breakdown of this Notebook:\n",
    "- Building an ANN from scratch\n",
    "- Calling network from .py File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Background on the Dataset: MNIST Digits.\n",
    "\n",
    "The dataset can be obtain from the link: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "The MNIST Digits dataset contains 70,000 greyscale images that have 28 x 28 pixels for each of the image. This dataset has been a reference set over the last few years to test and improve methods for this recognition task. The Input vector for the network works out to be 28 x 28 = 784 values and it has an output of 10 values (where there are 10 different digits ranging from 0 to 9). Further, the number of hidden layers for this network will be up to the modeller. \n",
    "\n",
    "## 1.2 - Loading in the Dataset:\n",
    "\n",
    "The data can also be directly loaded in by using the the \"minst\" Python module. To install -> https://pypi.org/project/mnist/ or \"pip install mnist\" \n",
    "The data should be prepared by splitting into two sets that are the training aand testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required Libraries:\n",
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "seed_nb = 42\n",
    "\n",
    "np.random.seed(seed_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Training dataset:\n",
    "X_train, y_train = mnist.train_images(), mnist.train_labels()\n",
    "\n",
    "# Load in the Testing dataset:\n",
    "X_test, y_test = mnist.test_images(), mnist.test_labels()\n",
    "\n",
    "# Set the Number of Classes:\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect:\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect:\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Visualise the data:\n",
    "\n",
    "Here, the \"matplotlib\" library will be used to visualise an image from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image index taken is: 7270\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEH0lEQVR4nO3dsS5sCxSA4Ts3xyR0GiJRaHQSWj2d59R4Dc20iI6aTiYaCnNfgD0nBvPP9X2llb2zmz8rOSuO0Ww2+wfo+XfZHwC8T5wQJU6IEidEiROi/syZ+6dc+H6j935oc0KUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6Lm/QlAVszBwcHg/PX1dXB+cXHx4ezw8PBT38Tn2JwQJU6IEidEiROixAlR4oQocUKUO+eKubm5GZzf3t4Ozmez2eD84eHhw5k758+yOSFKnBAlTogSJ0SJE6LECVHihCh3zhUz7045b87qsDkhSpwQJU6IEidEiROixAlRTikr5vr6etmfwA+xOSFKnBAlTogSJ0SJE6LECVHihCh3zhXjzvl72JwQJU6IEidEiROixAlR4oQocUKUO+eKubu7W/Yn8ENsTogSJ0SJE6LECVHihChxQpQ4Icqdc8VMJpOFnh+Px4Pz7e3thd7P17E5IUqcECVOiBInRIkTosQJUeKEKHfOX2ZjY2NwfnR09ENfwjw2J0SJE6LECVHihChxQpQ4IcopJWY6nQ7OX15eFnr/1tbWQs/zc2xOiBInRIkTosQJUeKEKHFClDghyp0z5urqanD++Pi40PtPT08Xep6fY3NClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVF+n/OX2dvbW/Yn8JdsTogSJ0SJE6LECVHihChxQpQ4Icqd85cZjUbL/gT+ks0JUeKEKHFClDghSpwQJU6IckqJOT8//9b3Hx8ff+v7+To2J0SJE6LECVHihChxQpQ4IUqcEOXOGTOZTJb9CUTYnBAlTogSJ0SJE6LECVHihChxQtRoNpsNzQeHfL3Nzc3B+dPT0+B8d3d3cH5/fz84X1tbG5zzLd79/0ptTogSJ0SJE6LECVHihChxQpQ4Icrvc/7PzLuTumOuDpsTosQJUeKEKHFClDghSpwQ5ZSyBJeXlx/OptPpQu8+Oztb6Hk6bE6IEidEiROixAlR4oQocUKUOCHKnXMJnp+fP5y9vb0t9O6Tk5OFnqfD5oQocUKUOCFKnBAlTogSJ0SJE6LcOZdgZ2fnw9l4PB58dn19fXC+v7//qW+ix+aEKHFClDghSpwQJU6IEidEiROiRrPZbGg+OAS+xOi9H9qcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqD9z5u/+aTLg+9mcECVOiBInRIkTosQJUeKEqP8AlI5VPk2EYDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab the image, by index:\n",
    "img_idx = np.random.randint(low = 0, high = X_test.shape[0])\n",
    "print('The image index taken is: ' + str(img_idx))\n",
    "\n",
    "# Plot:\n",
    "plt.imshow(X_test[img_idx], cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot 10 of the Digits:\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    img_idx = np.argwhere(y_test == i)[0]\n",
    "    plottable_image = np.reshape(X_test[img_idx], (28, 28))\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.imshow(plottable_image, cmap = matplotlib.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Dataset Preprocessing:\n",
    "\n",
    "Transform the images into the required column vectors to be used as the input for the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values between 0 and 255\n"
     ]
    }
   ],
   "source": [
    "# Flatten the data into a single row of vectors:\n",
    "X_train, X_test = X_train.reshape(-1, 28 * 28), X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# Check out the Pixel Values:\n",
    "print(\"Pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized pixel values between 0.0 and 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise the input data: scaling it between 0 and 1.\n",
    "X_train, X_test = X_train / 255., X_test / 255.\n",
    "print(\"Normalized pixel values between {} and {}\".format(X_train.min(), X_train.max()))\n",
    "\n",
    "# Inspect:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the labels:\n",
    "y_train = np.eye(nb_classes)[y_train]\n",
    "\n",
    "# Inpsect:\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Summary of the Training process:\n",
    "\n",
    "1. Select \"n\" amount of training images at a time (out of the whole training set) and input them to the network.\n",
    "2. Compute and backpropagate the loss. This is done by using chain rule to obtain the derivatives w.r.t the parameters of the layers.\n",
    "3. Update the parameters with the corresponding derivative(s) values that is scaled according to the learning rate.\n",
    "4. Repeat the steps 1 to 3 for the whole training set. Meaning the training is done in batches.\n",
    "5. Repeat the steps 1 to 4 until the network converges to a solution, or set a limited number of iterations (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Classes from the \"NeuralNetwork_Utilities.py\" file:\n",
    "from NeuralNetwork_Utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Traing the Simple Network model on the dataset:\n",
    "\n",
    "Here, the SimpleNetwork will be instantiated as a network with 2 hidden layers. It will take an input of flattened images and ouput a 10 value vector that represents the prediction of which image belonging to each of the class. The higher the ouptut value, means that the stronger the network believes that the image belongs to that certain class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Network:\n",
    "mnist_classifier = SimpleNetwork(num_inputs = X_train.shape[1],\n",
    "                                 num_outputs = nb_classes,\n",
    "                                 hidden_layers_sizes = [64, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Get a Baseline of the Un-trained model performance:\n",
    "\n",
    "Performance of the network can be found by calculating the loss over the training set and the accuracy reached over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions the model made from the training set:\n",
    "predictions = mnist_classifier.forward(x = X_train)\n",
    "\n",
    "# Compute the loss of the un-trained model:\n",
    "loss_untrained = mnist_classifier.loss_func(pred = predictions,\n",
    "                                            target = y_train)\n",
    "\n",
    "# Compute the accuracy of the un-trained model:\n",
    "acc_untrained = mnist_classifier.evaluate_accuracy(X_val = X_test, \n",
    "                                                   y_val = y_test)\n",
    "\n",
    "# Print:\n",
    "print(\"Untrained model performs with: training loss = {:.6f} | val accuracy = {:.2f}%\".format(\n",
    "    loss_untrained, acc_untrained * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Train the model and Validate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time calculation\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies = mnist_classifier.train(X_train = X_train, \n",
    "                                            y_train = y_train, \n",
    "                                            X_val = X_test, \n",
    "                                            y_val = y_test, \n",
    "                                            batch_size = 32, \n",
    "                                            nb_epochs = 500, \n",
    "                                            learning_rate = 0.001, \n",
    "                                            print_frequency = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time check:\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} minutes'.format(round(stop - start, 2)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = accuracies[np.argmax(accuracies)]\n",
    "print(\"The highest accuracy score found was: {}%\".format(round(max_acc, 4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The training completed relatively quickly as it is only running on the CPU. The highest accuracy achieved was 94.76% and this represents excellent performance.\n",
    "\n",
    "NOT: CPU specs: 2.6Ghz 6-core 12-threads, but it only utilised 6 threads aand turbo to 2.9Ghz for all the cores during this training task.\n",
    "\n",
    "## 4.4 - Plot the Lossess and Accuracies over the training epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies = [loss_untrained] + losses, [acc_untrained] + accuracies\n",
    "fig, ax_loss = plt.subplots()\n",
    "\n",
    "# Instantiate the FIRST axes:\n",
    "color = 'red'\n",
    "ax_loss.set_xlim([0, 510])\n",
    "ax_loss.set_xlabel('Epochs')\n",
    "ax_loss.set_ylabel('Training Loss', color=color)\n",
    "ax_loss.plot(losses, color=color)\n",
    "ax_loss.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Instantiate a SECOND axes that shares the same x-axis\n",
    "ax_acc = ax_loss.twinx()  \n",
    "color = 'blue'\n",
    "ax_acc.set_xlim([0, 510])\n",
    "ax_acc.set_ylim([0, 1])\n",
    "ax_acc.set_ylabel('Val Accuracy', color=color)\n",
    "ax_acc.plot(accuracies, color=color)\n",
    "ax_acc.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The network's convergence is very quick and proceeded to increase its accuracy at a slower pace until reaching the end of 500 epochs of training. Judging from the curve of the line, it can be seen that a more accurate model can be obtained by increasing the number of training epochs. \n",
    "\n",
    "## 4.5 - Longer training times:\n",
    "\n",
    "Let's find out if a higher accuracy can be reached by increasing the number of epochs. The new model will be called \"mnist_classifier_LTT\" where LTT stands for Longer Training Times. The number of epochs will be set to 1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Network:\n",
    "mnist_classifier_LTT = SimpleNetwork(num_inputs = X_train.shape[1],\n",
    "                                 num_outputs = nb_classes,\n",
    "                                 hidden_layers_sizes = [64, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time calculation\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies = mnist_classifier_LTT.train(X_train = X_train, \n",
    "                                            y_train = y_train, \n",
    "                                            X_val = X_test, \n",
    "                                            y_val = y_test, \n",
    "                                            batch_size = 32, \n",
    "                                            nb_epochs = 1000, \n",
    "                                            learning_rate = 0.001, \n",
    "                                            print_frequency = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time check:\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} minutes'.format(round(stop - start, 2)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = accuracies[np.argmax(accuracies)]\n",
    "print(\"The highest accuracy score found was: {}%\".format(round(max_acc, 4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "## 4.6 - Increasing the number of hidden layers:\n",
    "\n",
    "Here, the number of hidden layers will be reconfigured to [128, 64, 32]. The new model will be called \"mnist_classifier_MHL\" where MHL stands for More Hidden Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Network:\n",
    "mnist_classifier_MHL = SimpleNetwork(num_inputs = X_train.shape[1],\n",
    "                                 num_outputs = nb_classes,\n",
    "                                 hidden_layers_sizes = [128, 64, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time calculation\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies = mnist_classifier_MHL.train(X_train = X_train, \n",
    "                                            y_train = y_train, \n",
    "                                            X_val = X_test, \n",
    "                                            y_val = y_test, \n",
    "                                            batch_size = 32, \n",
    "                                            nb_epochs = 500, \n",
    "                                            learning_rate = 0.001, \n",
    "                                            print_frequency = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running time check\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {} minutes'.format(round(stop - start, 2)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = accuracies[np.argmax(accuracies)]\n",
    "print(\"The highest accuracy score found was: {}%\".format(round(max_acc, 4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "Here, the model was experimented with more hidden layers. The idea was to have more nodes to capture the features of the dataset, but it would seem like more hidden layers and nodes does not increase the accuracy of the mode.\n",
    "\n",
    "Further testing can be conducted by listing out the hyperparameters (layer sizes, learning rate, batch sizes and activation functions) and run the model through them. The model with the greatest score would be chosen. Other thoughts and considerations would be the amount of compute time that would be required if the model complexity increases. In these cases, it would be better to utilise a simpler model if the increases in model performance is not great enough to justify the model complexity. \n",
    "\n",
    "## 5 - Summary:\n",
    "\n",
    "This project ventures into building a neural network from scratch and I am able to appreciate its framework and how it works. I was able to learn and further develop my current understanding in neural networks, where more specifically, the Object oriented programming side of the network itself. Further explorations can consist of experimenting with the hyperparameters, like layer sizes, learning rate, batch sizes and activation functions, to tune the model to perfrom much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
